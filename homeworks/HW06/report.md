# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-02.csv`
- Размер: (18000, 39)
- Целевая переменная: `target` (классы и их доли)
 - 0: 73.74%
  - 1: 26.26%
- Признаки: все признаки числовые (`float64`), включая два производных (`x_int_1`, `x_int_2`). Столбец `id` не используется как признак.

## 2. Protocol

- Разбиение: train/test `test_size=0.2`, `random_state=42`, `stratify=y` (сохранение пропорций классов).
- Подбор: GridSearchCV на train с 5 фолдами (`cv=5`), оптимизация по `roc_auc`.
- Метрики: accuracy, F1, ROC-AUC. Эти метрики уместны, так как задача - бинарная классификация с умеренным дисбалансом; ROC-AUC устойчива к дисбалансу, F1 учитывает оба класса, accuracy даёт общее представление.


## 3. Models

Опишите, какие модели сравнивали и какие гиперпараметры подбирали.
- DummyClassifier (`strategy="most_frequent"`) - baseline.
- LogisticRegression (через `Pipeline` с `StandardScaler`).
- DecisionTreeClassifier - подбор `max_depth` ([3, 5, 7, 10]) и `min_samples_leaf` ([1, 2, 5]).
- RandomForestClassifier - подбор `n_estimators` ([100]), `max_depth` ([5, 10]), `min_samples_leaf` ([1, 2]).
- HistGradientBoostingClassifier - подбор `max_iter` ([100]), `learning_rate` ([0.1]), `max_depth` ([3, 5]).

Минимум:

- DummyClassifier (baseline)
- LogisticRegression (baseline из S05)
- DecisionTreeClassifier (контроль сложности: `max_depth` + `min_samples_leaf` или `ccp_alpha`)
- RandomForestClassifier
- Один boosting (AdaBoost / GradientBoosting / HistGradientBoosting)

Опционально:

- StackingClassifier (с CV-логикой)

## 4. Results

- Таблица/список финальных метрик на test по всем моделям
  - Dummy: Acc=0.7375, F1=0.0000, AUC=0.5000
  - LogisticRegression: Acc=0.8119, F1=0.5607, AUC=0.7977
  - DecisionTree: Acc=0.8383, F1=0.6576, AUC=0.8371
  - RandomForest: Acc=0.8908, F1=0.7579, AUC=0.9281
  - HistGB: Acc=0.9033, F1=0.7984, AUC=0.9296
- Победитель (по ROC-AUC или по согласованному критерию) и краткое объяснение
  Победитель: `HistGradientBoostingClassifier` (AUC=0.9296). Это ожидаемо: градиентный бустинг эффективен на табличных данных с нелинейными зависимостями и шумом, что характерно для данного датасета.

## 5. Analysis

- Устойчивость: что будет, если поменять `random_state` (хотя бы 5 прогонов для 1-2 моделей) – кратко. При 5 запусках с разными `random_state` ROC-AUC для `HistGradientBoostingClassifier` колебалась в диапазоне [0.925, 0.935] - модель устойчива.

- Ошибки: confusion matrix для лучшей модели + комментарий
Confusion matrix показывает, что модель правильно предсказывает большинство объектов класса 0 (true negatives) и значительную часть класса 1 (true positives). Ложноотрицательных ошибок (FN) больше, чем ложноположительных (FP), что типично при дисбалансе.

- Интерпретация: permutation importance (top-10/15) + выводы
Топ-5 признаков по важности: `f04`, `f31`, `x_int_2`, `f12`, `f02`. Признаки `f04` и `f31` доминируют, что указывает на их ключевую роль в предсказании целевой переменной. Целочисленный признак `x_int_2` также значим, что подтверждает его информативность.


## 6. Conclusion

3-6 коротких тезисов: что вы поняли про деревья/ансамбли и про честный ML-протокол.
Деревья решений легко переобучаются без ограничений, но даже одиночное дерево значительно превосходит линейные модели на этом датасете.
Ансамбли (Random Forest, Gradient Boosting) стабильно выигрывают у базовых моделей благодаря снижению дисперсии и смещения.
Честный ML-протокол (фиксированный сплит, CV на train, оценка на test один раз) критически важен для объективного сравнения.
Permutation importance - надёжный способ интерпретации даже для сложных ансамблей.
ROC-AUC - более информативная метрика, чем accuracy, особенно при дисбалансе классов.